{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-02T11:11:07.570671300Z",
     "start_time": "2023-09-02T11:10:56.941373200Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizer, BertForSequenceClassification, AdamW\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T11:13:39.691273700Z",
     "start_time": "2023-09-02T11:13:39.644222700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/English_scores/sentences.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T08:24:59.233040400Z",
     "start_time": "2023-09-02T08:24:59.091015500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  level  \\\n0  ben on phone michelle, please don t hang up. j...      1   \n1  your wallet. given as how i saved your life, i...      1   \n2  and make sure they re okay. michelle, they re ...      1   \n3  he s sorry for, correct? totally. let s go. ba...      1   \n4  possible. i heard one earlier. above my room. ...      1   \n\n                       movie  \n0  10_Cloverfield_lane(2016)  \n1  10_Cloverfield_lane(2016)  \n2  10_Cloverfield_lane(2016)  \n3  10_Cloverfield_lane(2016)  \n4  10_Cloverfield_lane(2016)  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>level</th>\n      <th>movie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ben on phone michelle, please don t hang up. j...</td>\n      <td>1</td>\n      <td>10_Cloverfield_lane(2016)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>your wallet. given as how i saved your life, i...</td>\n      <td>1</td>\n      <td>10_Cloverfield_lane(2016)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>and make sure they re okay. michelle, they re ...</td>\n      <td>1</td>\n      <td>10_Cloverfield_lane(2016)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>he s sorry for, correct? totally. let s go. ba...</td>\n      <td>1</td>\n      <td>10_Cloverfield_lane(2016)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>possible. i heard one earlier. above my room. ...</td>\n      <td>1</td>\n      <td>10_Cloverfield_lane(2016)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T08:25:03.663896100Z",
     "start_time": "2023-09-02T08:25:03.616799700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "level\n2    3216\n1    1966\n0    1166\n3    1156\nName: count, dtype: int64"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['level'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T10:43:50.398434700Z",
     "start_time": "2023-08-31T10:43:50.335683200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'MPNetTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "bert = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "tokenizer = BertTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T11:13:23.465138600Z",
     "start_time": "2023-09-02T11:13:21.153885Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['level']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T08:25:14.512306400Z",
     "start_time": "2023-09-02T08:25:14.506765900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T08:31:34.785696700Z",
     "start_time": "2023-09-02T08:31:34.754170400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop=True).astype(str)\n",
    "X_test = X_test.reset_index(drop=True).astype(str)\n",
    "\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T08:31:38.034193800Z",
     "start_time": "2023-09-02T08:31:38.030747900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    X_train.values,\n",
    "    max_length = 256,\n",
    "    padding = 'max_length',\n",
    "    truncation = True\n",
    ")\n",
    "\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    X_test.values,\n",
    "    max_length = 256,\n",
    "    padding = 'max_length',\n",
    "    truncation = True\n",
    ")\n",
    "\n",
    "# tokens_test = tokenizer.batch_encode_plus(\n",
    "#     test_text.values,\n",
    "#     max_length = 256,\n",
    "#     padding = 'max_length',\n",
    "#     truncation = True\n",
    "# )\n",
    "\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(y_train.values)\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(y_test.values)\n",
    "\n",
    "# test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "# test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "# test_y = torch.tensor(test_labels.values)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n",
    "\n",
    "val_data =  TensorDataset(val_seq, val_mask, val_y)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size = batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T08:33:01.744404300Z",
     "start_time": "2023-09-02T08:32:30.532014500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "class BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "        self.fc2 = nn.Linear(512,4)\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, sent_id, mask):\n",
    "        _, cls_hs = self.bert(sent_id, attention_mask = mask, return_dict = False)\n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T11:13:26.657538Z",
     "start_time": "2023-09-02T11:13:26.626163200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model = BERT_Arch(bert)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr= 1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T08:23:48.014092500Z",
     "start_time": "2023-09-02T08:23:47.726734800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model, open('models/model.pkl', 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T08:24:24.190907900Z",
     "start_time": "2023-09-02T08:24:23.112233400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.60891938 0.95422177 0.58333333 1.62283737]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=sorted(y.unique()), y=y)\n",
    "print(class_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T10:44:23.670247600Z",
     "start_time": "2023-08-31T10:44:23.655416Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "weights = weights.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T10:44:23.676687300Z",
     "start_time": "2023-08-31T10:44:23.665124300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss(weight=weights)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T10:44:23.681195Z",
     "start_time": "2023-08-31T10:44:23.670247600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    total_preds = []\n",
    "\n",
    "    for step, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        model.zero_grad()\n",
    "        preds = model(sent_id, mask)\n",
    "\n",
    "        loss = cross_entropy(preds, labels)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        total_preds.append(preds)\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    total_preds = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T10:44:23.714421600Z",
     "start_time": "2023-08-31T10:44:23.681195Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    total_loss, total_accuracy = 0,0\n",
    "    total_preds = []\n",
    "\n",
    "    for step, batch in tqdm(enumerate(val_dataloader), total = len(val_dataloader)):\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model(sent_id, mask)\n",
    "            loss = cross_entropy(preds, labels)\n",
    "            total_loss = total_loss + loss.item()\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    avg_loss = total_loss / len(val_dataloader)\n",
    "    total_preds = np.concatenate(total_preds, axis = 0)\n",
    "\n",
    "    return avg_loss, total_preds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T10:44:23.730050800Z",
     "start_time": "2023-08-31T10:44:23.685070400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "epochs = 50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T10:44:23.730050800Z",
     "start_time": "2023-08-31T10:44:23.697110800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch1 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:08<00:00, 10.90it/s]\n",
      "100%|██████████| 188/188 [00:13<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 1.253\n",
      "Validation loss: 1.183\n",
      "\n",
      " Epoch2 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:00<00:00, 12.32it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 1.173\n",
      "Validation loss: 1.160\n",
      "\n",
      " Epoch3 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.29it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 1.146\n",
      "Validation loss: 1.149\n",
      "\n",
      " Epoch4 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.26it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 1.133\n",
      "Validation loss: 1.159\n",
      "\n",
      " Epoch5 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.24it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 1.110\n",
      "Validation loss: 1.143\n",
      "\n",
      " Epoch6 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.23it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 1.091\n",
      "Validation loss: 1.140\n",
      "\n",
      " Epoch7 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.25it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 1.082\n",
      "Validation loss: 1.131\n",
      "\n",
      " Epoch8 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.24it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 1.064\n",
      "Validation loss: 1.126\n",
      "\n",
      " Epoch9 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.23it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 1.045\n",
      "Validation loss: 1.125\n",
      "\n",
      " Epoch10 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.24it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 1.031\n",
      "Validation loss: 1.110\n",
      "\n",
      " Epoch11 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.23it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 1.013\n",
      "Validation loss: 1.109\n",
      "\n",
      " Epoch12 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.22it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 1.003\n",
      "Validation loss: 1.111\n",
      "\n",
      " Epoch13 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.23it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.988\n",
      "Validation loss: 1.113\n",
      "\n",
      " Epoch14 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.23it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.978\n",
      "Validation loss: 1.104\n",
      "\n",
      " Epoch15 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.22it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.966\n",
      "Validation loss: 1.104\n",
      "\n",
      " Epoch16 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.21it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.954\n",
      "Validation loss: 1.098\n",
      "\n",
      " Epoch17 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.22it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.947\n",
      "Validation loss: 1.101\n",
      "\n",
      " Epoch18 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.21it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.932\n",
      "Validation loss: 1.099\n",
      "\n",
      " Epoch19 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.22it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.931\n",
      "Validation loss: 1.093\n",
      "\n",
      " Epoch20 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.20it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.915\n",
      "Validation loss: 1.105\n",
      "\n",
      " Epoch21 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.20it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.915\n",
      "Validation loss: 1.094\n",
      "\n",
      " Epoch22 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.21it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.898\n",
      "Validation loss: 1.109\n",
      "\n",
      " Epoch23 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.21it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.899\n",
      "Validation loss: 1.099\n",
      "\n",
      " Epoch24 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.21it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.890\n",
      "Validation loss: 1.090\n",
      "\n",
      " Epoch25 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.21it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.878\n",
      "Validation loss: 1.103\n",
      "\n",
      " Epoch26 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.22it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.880\n",
      "Validation loss: 1.098\n",
      "\n",
      " Epoch27 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.21it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.875\n",
      "Validation loss: 1.096\n",
      "\n",
      " Epoch28 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.22it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.873\n",
      "Validation loss: 1.099\n",
      "\n",
      " Epoch29 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.21it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.861\n",
      "Validation loss: 1.089\n",
      "\n",
      " Epoch30 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.21it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.858\n",
      "Validation loss: 1.096\n",
      "\n",
      " Epoch31 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.21it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.857\n",
      "Validation loss: 1.091\n",
      "\n",
      " Epoch32 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.19it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.850\n",
      "Validation loss: 1.093\n",
      "\n",
      " Epoch33 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.21it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.854\n",
      "Validation loss: 1.083\n",
      "\n",
      " Epoch34 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.21it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.845\n",
      "Validation loss: 1.081\n",
      "\n",
      " Epoch35 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.22it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.841\n",
      "Validation loss: 1.084\n",
      "\n",
      " Epoch36 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.22it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.837\n",
      "Validation loss: 1.087\n",
      "\n",
      " Epoch37 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.21it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.833\n",
      "Validation loss: 1.085\n",
      "\n",
      " Epoch38 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.23it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.833\n",
      "Validation loss: 1.091\n",
      "\n",
      " Epoch39 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.20it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.830\n",
      "Validation loss: 1.098\n",
      "\n",
      " Epoch40 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.21it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.829\n",
      "Validation loss: 1.090\n",
      "\n",
      " Epoch41 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.22it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.823\n",
      "Validation loss: 1.083\n",
      "\n",
      " Epoch42 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.21it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.821\n",
      "Validation loss: 1.082\n",
      "\n",
      " Epoch43 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.22it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.820\n",
      "Validation loss: 1.078\n",
      "\n",
      " Epoch44 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.22it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.821\n",
      "Validation loss: 1.081\n",
      "\n",
      " Epoch45 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.22it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.818\n",
      "Validation loss: 1.085\n",
      "\n",
      " Epoch46 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.21it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.817\n",
      "Validation loss: 1.086\n",
      "\n",
      " Epoch47 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.22it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.815\n",
      "Validation loss: 1.093\n",
      "\n",
      " Epoch48 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.21it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.812\n",
      "Validation loss: 1.088\n",
      "\n",
      " Epoch49 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.21it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.814\n",
      "Validation loss: 1.091\n",
      "\n",
      " Epoch50 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [01:01<00:00, 12.21it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.812\n",
      "Validation loss: 1.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('\\n Epoch{:} / {:}'.format(epoch+1, epochs))\n",
    "\n",
    "    train_loss, _ = train()\n",
    "    valid_loss, _ = evaluate()\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    print(f'\\nTraining loss: {train_loss:.3f}')\n",
    "    print(f'Validation loss: {valid_loss:.3f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T11:47:42.515183800Z",
     "start_time": "2023-08-31T10:44:23.699417700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = 'models'\n",
    "path_model = os.path.join(path, 'model.pkl')\n",
    "path_weights = os.path.join(path, 'saved_weights.pt')\n",
    "\n",
    "# Now, load the model and weights\n",
    "model = pickle.load(open(path_model, 'rb'))\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(path_weights))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T11:13:49.047Z",
     "start_time": "2023-09-02T11:13:46.402163100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({'text': X_test, 'level': y_test})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T08:33:01.749573900Z",
     "start_time": "2023-09-02T08:33:01.744404300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "list_seq = np.array_split(val_seq, 256)\n",
    "list_mask = np.array_split(val_mask, 256)\n",
    "\n",
    "predictions = []\n",
    "for seq_elem, mask_elem in zip(list_seq, list_mask):\n",
    "    with torch.no_grad():\n",
    "        preds = model(seq_elem.to(device), mask_elem.to(device))\n",
    "        predictions.append(preds.detach().cpu().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T10:18:35.791822Z",
     "start_time": "2023-09-02T10:18:20.305214500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# concat predictions\n",
    "predictions = np.concatenate(predictions, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T10:18:37.287683800Z",
     "start_time": "2023-09-02T10:18:37.239954100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(predictions.argmax(axis=1).mean().round())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T10:37:35.480245700Z",
     "start_time": "2023-09-02T10:37:35.464349700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "test_df['confidence'] = predictions.max(axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T10:18:38.150314900Z",
     "start_time": "2023-09-02T10:18:38.145302200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "test_df['prediction'] = predictions.argmax(axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T10:18:38.596232100Z",
     "start_time": "2023-09-02T10:18:38.591942300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   text  level  confidence  \\\n0     for christmas. that s convenient because i got...      1    0.820066   \n1     s usually right after somebody died. i take it...      2    0.596158   \n2     mr. reede, you may proceed. how? your honor, w...      1    0.998492   \n3     flower. and we will rule this jungle. i will p...      0    0.978000   \n4     that, that was a party. not this. you know, pe...      2    0.998495   \n...                                                 ...    ...         ...   \n1496  when i m not with daniel, i m better. and. i m...      1    0.886949   \n1497  would be waiting for us when we got back. we l...      1    0.983142   \n1498  that bell. you re damn right i m not ringing t...      3    0.907795   \n1499  if you want to get technical, there s memorial...      0    0.969342   \n1500  connor you do? yeah, i do. connor you do? yes....      2    0.999955   \n\n      prediction  miss_value  \n0              1           0  \n1              2           0  \n2              1           0  \n3              0           0  \n4              2           0  \n...          ...         ...  \n1496           2           1  \n1497           1           0  \n1498           2           1  \n1499           1           1  \n1500           2           0  \n\n[1501 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>level</th>\n      <th>confidence</th>\n      <th>prediction</th>\n      <th>miss_value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>for christmas. that s convenient because i got...</td>\n      <td>1</td>\n      <td>0.820066</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>s usually right after somebody died. i take it...</td>\n      <td>2</td>\n      <td>0.596158</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mr. reede, you may proceed. how? your honor, w...</td>\n      <td>1</td>\n      <td>0.998492</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>flower. and we will rule this jungle. i will p...</td>\n      <td>0</td>\n      <td>0.978000</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>that, that was a party. not this. you know, pe...</td>\n      <td>2</td>\n      <td>0.998495</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1496</th>\n      <td>when i m not with daniel, i m better. and. i m...</td>\n      <td>1</td>\n      <td>0.886949</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1497</th>\n      <td>would be waiting for us when we got back. we l...</td>\n      <td>1</td>\n      <td>0.983142</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1498</th>\n      <td>that bell. you re damn right i m not ringing t...</td>\n      <td>3</td>\n      <td>0.907795</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1499</th>\n      <td>if you want to get technical, there s memorial...</td>\n      <td>0</td>\n      <td>0.969342</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1500</th>\n      <td>connor you do? yeah, i do. connor you do? yes....</td>\n      <td>2</td>\n      <td>0.999955</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1501 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T10:18:39.046806400Z",
     "start_time": "2023-09-02T10:18:39.030843200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       233\n",
      "           1       0.61      0.68      0.65       393\n",
      "           2       0.73      0.70      0.71       644\n",
      "           3       0.60      0.56      0.58       231\n",
      "\n",
      "    accuracy                           0.67      1501\n",
      "   macro avg       0.65      0.65      0.65      1501\n",
      "weighted avg       0.67      0.67      0.67      1501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['level'], test_df['prediction']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T10:18:39.861707Z",
     "start_time": "2023-09-02T10:18:39.830571100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "test_df['miss_value'] = abs(test_df['level'] - test_df['prediction'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T10:18:51.904889Z",
     "start_time": "2023-09-02T10:18:51.889224200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "miss_value\n0    999\n1    392\n2     99\n3     11\nName: count, dtype: int64"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['miss_value'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T10:18:52.367568800Z",
     "start_time": "2023-09-02T10:18:52.360271100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9267155229846769"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df['miss_value'].isin([0, 1])]) / len(test_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-02T10:18:55.807011Z",
     "start_time": "2023-09-02T10:18:55.775265700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T11:47:58.143718600Z",
     "start_time": "2023-08-31T11:47:58.117303900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T11:47:58.143718600Z",
     "start_time": "2023-08-31T11:47:58.120163200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T11:47:58.184982800Z",
     "start_time": "2023-08-31T11:47:58.124888Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T11:47:58.263113200Z",
     "start_time": "2023-08-31T11:47:58.124888Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T11:47:58.263113200Z",
     "start_time": "2023-08-31T11:47:58.128801300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T11:47:58.263113200Z",
     "start_time": "2023-08-31T11:47:58.136588100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T11:47:58.263113200Z",
     "start_time": "2023-08-31T11:47:58.140412200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T11:47:58.263113200Z",
     "start_time": "2023-08-31T11:47:58.143718600Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
